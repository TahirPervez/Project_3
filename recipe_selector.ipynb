{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pantry_window'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mui\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkitchen_ui\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KitchenApp\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mui\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpantry_window\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PantryWindow\n\u001b[0;32m     11\u001b[0m instance \u001b[38;5;241m=\u001b[39m KitchenApp()\n",
      "File \u001b[1;32mc:\\Users\\fsgin\\OneDrive\\Documents\\School\\AI Bootcamp\\Project_3\\scripts\\ui\\kitchen_ui.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpantry_window\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PantryWindow\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstove_window\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StoveWindow\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcookbooks_window\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CookbooksWindow\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pantry_window'"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from scripts.ui.kitchen_ui import KitchenApp\n",
    "from scripts.ui.pantry_window import PantryWindow\n",
    "\n",
    "instance = KitchenApp()\n",
    "\n",
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "# Store the API key in a variable.\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(api_key=GEMINI_API_KEY,model=GEMINI_MODEL, temperature=0.3)\n",
    "\n",
    "format = \"\"\"\n",
    "You are helping me plan out my meals based on what I have. I want to provide you\n",
    "a list of ingredients that I know for a fact that I have, and your job is to\n",
    "help me determine a main course that I can make using what I have. In addition, \n",
    "a simple side dish to go with it is wanted if it is not a meal that would be \n",
    "eaten without any. I want you to tell me 3 recipes that can be made for the main \n",
    "course with what I tell you I have, and I will specify the one I want to get the \n",
    "full instructions for.\n",
    "\n",
    "When selecting the recipes to make, try to ensure that they are a different from\n",
    "eachother as possible, since if I'm not in the mood for a certain style of food, \n",
    "I still have a decent selection to choose from.\n",
    "\n",
    "These are ingredients I always keep on hand, and should be factored less: {staples}\n",
    "Fresh Ingredients: {fresh_ingredients}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=format\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# TODO: Pantry items where they are marked stable\n",
    "staples = \"\"\"\n",
    "Salt, oil, herbs and spices, \n",
    "condiments and sauces, bouillon cubes,\n",
    "pickles, pickled jalapenos, \n",
    "milk, eggs, mexican blend cheese, cheddar cheese\n",
    "canned beans, canned tomatos\n",
    "onions, garlic, \n",
    "dried pasta, dried rice, \n",
    "sandwich bread\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Pantry items where they are marked temprary / fresh\n",
    "ingredients = \"\"\"\n",
    "milk\n",
    "\"\"\"\n",
    "# ground beef, cornmeal, jalapenos, fritos\n",
    "\n",
    "pantry_data = instance.get_pantry_data()\n",
    "print(pantry_data)\n",
    "\n",
    "query = {\n",
    "    \"fresh_ingredients\":ingredients,\n",
    "    \"staples\":staples,\n",
    "}\n",
    "\n",
    "result = chain.invoke(query)[\"text\"]\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
